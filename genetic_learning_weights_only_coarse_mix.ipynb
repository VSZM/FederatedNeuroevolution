{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# based on https://towardsdatascience.com/artificial-neural-networks-optimization-using-genetic-algorithm-with-python-1fe8ed17733e\n",
    "from common import Trial, safe_log, nll, load_df, df_to_ML_data, timed_method\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout, Lambda\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.models import Sequential\n",
    "import keras_metrics\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import logging\n",
    "import random\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',level=logging.INFO, \n",
    "                    filename='genetic_learning_weights_only_coarse_mix.log', filemode='w+')\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()#device_count = {'GPU': 0})\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "config.gpu_options.allow_growth = True\n",
    "keras.backend.tensorflow_backend.set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_population(population_of_models):\n",
    "    population_vector = []\n",
    "    for model in population_of_models:\n",
    "        model_vector = []\n",
    "        for layer in model:\n",
    "            layer_vectorized = np.reshape(layer, newshape=(layer.size))\n",
    "            np.reshape(layer_vectorized, newshape=layer.shape)\n",
    "            model_vector.extend(layer_vectorized)\n",
    "        population_vector.append(model_vector)\n",
    "    return np.array(population_vector)\n",
    "\n",
    "def population_vector_to_models(population_vectors, reference_model):\n",
    "    models = []\n",
    "    model_idx = 0\n",
    "    for vector in population_vectors:\n",
    "        start = 0\n",
    "        end = 0\n",
    "        model = []\n",
    "        for reference_layer in reference_model:\n",
    "            end = end + reference_layer.size\n",
    "            layer_vector = vector[start:end]\n",
    "            layer = np.reshape(layer_vector, newshape=reference_layer.shape)\n",
    "            model.append(layer) \n",
    "            start = end\n",
    "        models.append(model)\n",
    "        model_idx = model_idx + 1\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('json_weights_bn_simple.pkl', 'rb') as f:\n",
    "    model_topology_json, weights = pickle.load(f)\n",
    "\n",
    "(model_topology_json, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = df_to_ML_data(load_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weights(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    for i in range(len(a)):\n",
    "        assert a[i].shape ==  b[i].shape\n",
    "\n",
    "@timed_method\n",
    "def create_model_programatically(weights = None):\n",
    "    input_shape = (64, 256, 1)\n",
    "    num_classes = 2\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, kernel_size=(1, 25),\n",
    "                     input_shape=input_shape))\n",
    "    model.add(BatchNormalization(momentum=0.1))\n",
    "    model.add(Conv2D(10, kernel_size=(64, 1)))\n",
    "    model.add(BatchNormalization(momentum=0.1))\n",
    "    model.add(Lambda(lambda x: x ** 2))\n",
    "    model.add(AveragePooling2D(pool_size=(1, 15), strides=(1, 1)))\n",
    "    model.add(Lambda(lambda x: safe_log(x)))\n",
    "    model.add(BatchNormalization(momentum=0.1))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(2, kernel_size=(1, 8), dilation_rate=(15, 1)))\n",
    "    model.add(BatchNormalization(momentum=0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    if weights != None:\n",
    "        check_weights(model.get_weights(), weights)\n",
    "\n",
    "        model.set_weights(weights)\n",
    "\n",
    "        \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=[keras_metrics.binary_f1_score(), metrics.binary_accuracy])\n",
    "                        #metrics.binary_accuracy, metrics.cosine_proximity, metrics.mean_absolute_error, \n",
    "                       #metrics.mean_absolute_percentage_error, metrics.mean_squared_error,\n",
    "                       #keras_metrics.precision(), keras_metrics.recall(), keras_metrics.binary_f1_score(), \n",
    "                       #keras_metrics.binary_false_negative(), keras_metrics.binary_false_positive(),\n",
    "                       #keras_metrics.binary_true_negative(), keras_metrics.binary_true_positive()\n",
    "                        #])\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "@timed_method\n",
    "def individual_fitness(model_topology_json, model_weights, X, y):\n",
    "    #keras_model = model_from_json(model_topology_json)\n",
    "    keras_model = create_model_programatically(model_weights)\n",
    "    result = keras_model.evaluate(X,y, verbose=0) \n",
    "    log.debug(result)\n",
    "    return result[1]\n",
    "    \n",
    "\n",
    "def population_fitness(model_topology_json, population_of_models, X, y):\n",
    "    fitness_scores = []\n",
    "    \n",
    "    for model_weights in population_of_models:#tqdm(population_of_models, desc='Current Population Fitness', position=1):\n",
    "        fitness_scores.append(individual_fitness(model_topology_json, model_weights, X, y))\n",
    "                          \n",
    "    return fitness_scores\n",
    "\n",
    "def fittest_parents_of_generation(population, fitness_scores, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = []\n",
    "    for _ in range(num_parents - 1):\n",
    "        max_fitness_idx = np.argmax(fitness_scores)\n",
    "        parents.append(population[max_fitness_idx])\n",
    "        del population[max_fitness_idx]\n",
    "        del fitness_scores[max_fitness_idx]\n",
    "    \n",
    "    # mixing in a lucky one.. because sometimes anyone can get lucky ;)\n",
    "    np.random.shuffle(population)\n",
    "    parents.append(population[0])\n",
    "\n",
    "    return parents\n",
    "\n",
    "#crossover that produces the offspring by taking the first half of it from the first parent \n",
    "# and taking the second half of it from the 2nd parent\n",
    "def crossover(parent_vectors, offsprings_size):\n",
    "    offsprings = np.empty((offsprings_size, len(parent_vectors[0])))\n",
    "    # The point at which crossover takes place between two parents. Usually, it is at the center.\n",
    "    crossover_point = int(len(parent_vectors[0]) / 2)\n",
    "    for k in range(offsprings_size):\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k % len(parent_vectors)\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1) % len(parent_vectors)\n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offsprings[k, 0:crossover_point] = parent_vectors[parent1_idx][0:crossover_point]\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offsprings[k, crossover_point:] = parent_vectors[parent2_idx][crossover_point:]\n",
    "    return offsprings\n",
    "\n",
    "\n",
    "def mutation(offsprings, mutation_chance=0.1, mutation_rate=1):\n",
    "    num_mutations = np.uint8(len(offsprings[0]) * mutation_chance)\n",
    "    mutation_indices = np.array(random.sample(range(0, len(offsprings[0])), num_mutations))\n",
    "    log.debug('Mutating indices = %s', mutation_indices)\n",
    "\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(len(offsprings)):\n",
    "        # The random value to be added to the gene.\n",
    "        mutation_value = np.random.uniform(-1.0 * mutation_rate, 1.0 * mutation_rate, 1)\n",
    "        offsprings[idx][mutation_indices] = offsprings[idx][mutation_indices] + mutation_value\n",
    "        \n",
    "    return offsprings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population_fitness(model_topology_json, [weights], X_train, y_train)\n",
    "#for i in range(100):\n",
    "individual_fitness(None, weights, X_test, y_test)\n",
    "#    if i % 5 == 0:\n",
    "#        K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genetic algorithm parameters:\n",
    "#    Mating Pool Size (Number of Parents)\n",
    "#    Population Size\n",
    "#    Number of Generations\n",
    "#    Mutation Percent\n",
    "\n",
    "\n",
    "population_size = 20 #sol_per_pop\n",
    "num_parents_mating = 8\n",
    "num_generations = 1000\n",
    "mutation_chance = 0.1\n",
    "mutation_rate = 2\n",
    "reference_weights = weights\n",
    "\n",
    "#Creating the initial population.\n",
    "population_weights = []\n",
    "for _ in range(0, population_size):\n",
    "    population_weights.append(create_model_programatically().get_weights())\n",
    "    \n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_fitness(None, population_weights[2], X_test, y_test)\n",
    "individual_fitness(None, population_weights[3], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_of_each_generation = []\n",
    "\n",
    "for generation in tqdm(range(num_generations), desc='Generations', position=0):\n",
    "\n",
    "    log.debug('Testing generation |%d| population: |%s|', generation, population_weights)\n",
    "    # Measuring the fitness of each chromosome in the population.\n",
    "    fitness_scores = population_fitness(None, population_weights, X_test, y_test)\n",
    "    \n",
    "    best_of_this_generation = max(fitness_scores)\n",
    "    best_of_each_generation.append(best_of_this_generation)\n",
    "    log.info(\"Best of geration |%d| has accuracy of |%f|\", generation, best_of_this_generation)\n",
    "    log.info('Fitness scores of this generation: |%s|', fitness_scores)\n",
    "    \n",
    "    \n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = fittest_parents_of_generation(population_weights.copy(), fitness_scores, num_parents_mating)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offsprings = crossover(vectorize_population(parents), len(population_weights) - num_parents_mating)\n",
    "\n",
    "    # Adding some variations to the offsrping using mutation.\n",
    "    offsprings = mutation(offsprings, mutation_chance=mutation_chance, mutation_rate=mutation_rate)\n",
    "\n",
    "    # Creating the new generation based on the parents and offspring.\n",
    "    population_weights = []\n",
    "    population_weights.extend(parents)\n",
    "    population_weights.extend(population_vector_to_models(offsprings, parents[0]))\n",
    "\n",
    "    #cleanup resources\n",
    "    K.clear_session()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_scores = population_fitness(None, population_weights, X_test, y_test)\n",
    "log.info(\"Accuracy of the best solution is : \", max(fitness_scores))\n",
    "log.info('Fitness scores of the last generation: |%s|', fitness_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.plot(best_of_each_generation, linewidth=5, color=\"black\")\n",
    "matplotlib.pyplot.xlabel(\"Iteration\", fontsize=20)\n",
    "matplotlib.pyplot.ylabel(\"Fitness\", fontsize=20)\n",
    "#matplotlib.pyplot.xticks(np.arange(0, num_generations+1, 100), fontsize=15)\n",
    "#matplotlib.pyplot.yticks(np.arange(0, 101, 5), fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"F:\\\\Tresorit\\\\01 - Startup Screen.mp3\", autoplay=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
