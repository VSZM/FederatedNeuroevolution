{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# based on https://towardsdatascience.com/artificial-neural-networks-optimization-using-genetic-algorithm-with-python-1fe8ed17733e\n",
    "# different crossover function: mean\n",
    "from common import Trial, safe_log, nll, load_df, df_to_ML_data, timed_method, ts\n",
    "\n",
    "\n",
    "from IPython.core.display import Javascript\n",
    "from IPython.display import display\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout, Lambda\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import binary_accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras_metrics\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import logging\n",
    "import random\n",
    "import sys\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',level=logging.INFO, \n",
    "                    filename='genetic_learning_weights_only_kernel_' + ts() + '.log', filemode='w+')\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "config = tf.ConfigProto()#device_count = {'GPU': 0})\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "config.gpu_options.allow_growth = True\n",
    "keras.backend.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('json_weights_shallow.pkl', 'rb') as f:\n",
    "    model_topology_json, weights = pickle.load(f)\n",
    "\n",
    "(model_topology_json, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = df_to_ML_data(load_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weights(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    for i in range(len(a)):\n",
    "        assert a[i].shape ==  b[i].shape\n",
    "\n",
    "def create_model_programatically(weights = None):\n",
    "    input_shape = (64, 256, 1)\n",
    "    num_classes = 2\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, kernel_size=(1, 25),\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(10, kernel_size=(64, 1)))\n",
    "    model.add(Lambda(lambda x: x ** 2))\n",
    "    model.add(AveragePooling2D(pool_size=(1, 15), strides=(1, 1)))\n",
    "    model.add(Lambda(lambda x: safe_log(x)))\n",
    "    model.add(Conv2D(2, kernel_size=(1, 8), dilation_rate=(15, 1)))\n",
    "    model.add(BatchNormalization(momentum=0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    if weights != None:\n",
    "        #check_weights(model.get_weights(), weights)\n",
    "\n",
    "        model.set_weights(weights)\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "def individual_fitness(model_topology_json, model_weights, X, y):\n",
    "    keras_model = create_model_programatically(model_weights)\n",
    "    y_pred = keras_model.predict(X, batch_size=512)\n",
    "    \n",
    "    m = tf.keras.metrics.BinaryAccuracy()\n",
    "    m.update_state(y, y_pred)\n",
    "\n",
    "    return K.mean(binary_accuracy(y, y_pred)).eval(session=K.get_session())\n",
    "    \n",
    "def population_fitness(model_topology_json, population_of_models, X, y):\n",
    "    fitness_scores = []\n",
    "    \n",
    "    for model_weights in population_of_models:#tqdm(population_of_models, desc='Current Population Fitness calculation progress', position=2):\n",
    "        fitness_scores.append(individual_fitness(model_topology_json, model_weights, X, y))\n",
    "                          \n",
    "    return fitness_scores\n",
    "\n",
    "def fittest_parents_of_generation(population, fitness_scores, num_parents, selector = np.argmin):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = []\n",
    "    for _ in range(num_parents - 1):\n",
    "        best_fitness_idx = selector(fitness_scores)\n",
    "        parents.append(population[best_fitness_idx])\n",
    "        del population[best_fitness_idx]\n",
    "        del fitness_scores[best_fitness_idx]\n",
    "    \n",
    "    # mixing in a lucky one.. because sometimes anyone can get lucky ;)\n",
    "    np.random.shuffle(population)\n",
    "    parents.append(population[0])\n",
    "\n",
    "    return parents\n",
    "\n",
    "\n",
    "# Mixing too models by keeping their kernel weights intact\n",
    "def kernelwise_mix(model_a, model_b):\n",
    "    mix = []\n",
    "    for i in range(len(model_a)):\n",
    "        layer_a = model_a[i]\n",
    "        layer_b = model_b[i]        \n",
    "        # choosing kernels\n",
    "        choice = np.random.randint(2, size = int(layer_a.size / layer_a.shape[-1])).reshape(layer_a.shape[:-1]).astype(bool)\n",
    "        # extending the chosen kernel bools to the level of single values\n",
    "        choice = np.repeat(choice, layer_a.shape[-1]).reshape(layer_a.shape)\n",
    "\n",
    "        layer_mix = np.where(choice, layer_a, layer_b)\n",
    "        mix.append(layer_mix)\n",
    "        \n",
    "    return mix\n",
    "\n",
    "# Creates offsprings by mixing the layers of the model weights\n",
    "def crossover(parent_models, offsprings_size):\n",
    "    offsprings = []\n",
    "    np.random.shuffle(parent_models)\n",
    "    for k in range(offsprings_size):\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k % len(parent_models)\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1) % len(parent_models)\n",
    "        # mix of each modell kernelwise\n",
    "        offsprings.append(kernelwise_mix(parent_models[parent1_idx], parent_models[parent2_idx]))\n",
    "    return offsprings\n",
    "\n",
    "def mutation(offsprings, mutation_chance=0.1, mutation_rate=1):\n",
    "\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for offspring in offsprings:\n",
    "        for layer in offspring:\n",
    "            trues = np.full(int(layer.size * mutation_chance), True)\n",
    "            falses = np.full(layer.size - trues.size, False)\n",
    "            mutation_indices = np.append(trues, falses)\n",
    "            np.random.shuffle(mutation_indices)\n",
    "            mutation_indices = mutation_indices.reshape(layer.shape)\n",
    "                \n",
    "            # The random value to be added to the gene.\n",
    "            mutation_multiplier = np.random.normal(loc=0.0, scale=0.01 * mutation_rate, size=1)\n",
    "            layer[mutation_indices] = layer[mutation_indices] + layer[mutation_indices] * mutation_multiplier\n",
    "        \n",
    "    return offsprings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population_fitness(model_topology_json, [weights], X_train, y_train)\n",
    "#for i in range(100):\n",
    "individual_fitness(None, weights, X_test, y_test)\n",
    "#    if i % 5 == 0:\n",
    "#        K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "population_size = 100 #sol_per_pop\n",
    "num_parents_mating = 8\n",
    "num_generations = 10000\n",
    "mutation_chance = 0.01\n",
    "mutation_rate = 5\n",
    "reference_weights = weights\n",
    "stuck_multiplier = 1\n",
    "stuck_evasion_rate = 1.5\n",
    "\n",
    "#Creating the initial population.\n",
    "if os.path.isfile('genetic_learning_weights_only_kernel_faster_weights.checkpoint'):\n",
    "    log.info('Resuming from previous checkpoint')\n",
    "    with open('genetic_learning_weights_only_kernel_faster_weights.checkpoint', 'rb') as f:\n",
    "        population_weights = pickle.load(f)\n",
    "else:\n",
    "    log.info('Creating random population')\n",
    "    population_weights = []\n",
    "    for _ in range(0, population_size):\n",
    "        population_weights.append(create_model_programatically().get_weights())\n",
    "    \n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_scores = population_fitness(None, population_weights, X_test, y_test)\n",
    "log.info(\"Accuracy of the best solution is : %f\", max(fitness_scores))\n",
    "log.info('Fitness scores of the last generation: |%s|', fitness_scores)\n",
    "\n",
    "best_model = population_weights[np.argmin(fitness_scores)]\n",
    "\n",
    "keras_model = create_model_programatically(best_model)\n",
    "predictions = keras_model.predict_classes(X_test)\n",
    "y_true = np.argmax(y_test, axis = 1)\n",
    "accuracy = accuracy_score(y_true, predictions)\n",
    "log.info('Best accuracy so far: %f', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'best_of_each_generation' in locals() or 'best_of_each_generation' in globals():\n",
    "    pass\n",
    "else:\n",
    "    best_of_each_generation = []\n",
    "\n",
    "for generation in tqdm(range(num_generations), desc='Generations progress', position=1):\n",
    "\n",
    "    log.debug('Testing generation |%d| population: |%s|', generation, population_weights)\n",
    "    # Measuring the fitness of each chromosome in the population.\n",
    "    fitness_scores = population_fitness(None, population_weights, X_train, y_train)\n",
    "    \n",
    "    best_of_this_generation = max(fitness_scores)\n",
    "    best_of_each_generation.append(best_of_this_generation)\n",
    "    log.info(\"Best of geration |%d| has accuracy of |%f|\", generation, best_of_this_generation)\n",
    "    log.info('Fitness scores of this generation: |%s|', fitness_scores)\n",
    "    \n",
    "    \n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = fittest_parents_of_generation(population_weights.copy(), fitness_scores, num_parents_mating)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offsprings = crossover(parents.copy(), len(population_weights) - num_parents_mating)\n",
    "\n",
    "    # Adding some variations to the offsrping using mutation.\n",
    "    offsprings = mutation(offsprings, mutation_chance=mutation_chance * stuck_multiplier, mutation_rate=mutation_rate * stuck_multiplier)\n",
    "\n",
    "    # Creating the new generation based on the parents and offspring.\n",
    "    population_weights = []\n",
    "    population_weights.extend(parents)\n",
    "    population_weights.extend(offsprings)\n",
    "\n",
    "    #cleanup resources\n",
    "    K.clear_session()\n",
    "    if generation > 0 and best_of_this_generation == best_of_each_generation[generation-1]:\n",
    "        stuck_multiplier *= stuck_evasion_rate\n",
    "        log.info('Stuck at local maximum, expanding mutation rate and chance by stuck multiplier of |%f|', stuck_multiplier)\n",
    "    else:\n",
    "        stuck_multiplier = 1\n",
    "\n",
    "    if generation % 10 == 0:\n",
    "        plot_learning(best_of_each_generation, num_generations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving weights\n",
    "with open('genetic_learning_weights_only_kernel_faster_weights.save','wb') as f:\n",
    "    pickle.dump(population_weights, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_scores = population_fitness(None, population_weights, X_test, y_test)\n",
    "log.info(\"Accuracy of the best solution is : %f\", max(fitness_scores))\n",
    "log.info('Fitness scores of the last generation: |%s|', fitness_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning(best_of_each_generation, num_generations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = population_weights[np.argmin(fitness_scores)]\n",
    "\n",
    "keras_model = create_model_programatically(best_model)\n",
    "predictions = keras_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"F:\\\\Tresorit\\\\01 - Startup Screen.mp3\", autoplay=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
